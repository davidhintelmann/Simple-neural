{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.rcParams[\"figure.figsize\"] = (1,1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCifar(filename):\n",
    "    with open('data/cifar-10-batches-py/'+filename, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='latin1')\n",
    "    feature = data['data']\n",
    "    label = data['labels']\n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1, labels_1 = loadCifar('data_batch_1')\n",
    "batch_2, labels_2 = loadCifar('data_batch_2')\n",
    "batch_3, labels_3 = loadCifar('data_batch_3')\n",
    "batch_4, labels_4 = loadCifar('data_batch_4')\n",
    "batch_5, labels_5 = loadCifar('data_batch_5')\n",
    "batch_test, labels_test = loadCifar('test_batch') \n",
    "\n",
    "features = np.concatenate([batch_1,batch_2,batch_3,batch_4,batch_5],0)\n",
    "labels_train = np.concatenate([labels_1,labels_2,labels_3,labels_4,labels_5],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapeData(batch):\n",
    "    assert batch.shape[1] == 3072\n",
    "    r = batch[:, 0:1024].reshape(batch.shape[0], 1, 32, 32)\n",
    "    g = batch[:, 1024:2048].reshape(batch.shape[0], 1, 32, 32)\n",
    "    b = batch[:, 2048:3072].reshape(batch.shape[0], 1, 32, 32)\n",
    "    rgb = np.concatenate([r,g,b], axis=1)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape #fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = shapeData(features)\n",
    "features_test = shapeData(batch_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "#labels_train = torch.from_numpy(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "a = np.transpose(features_train[12],(1,2,0))\n",
    "plt.imshow(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARarray(Dataset): \n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.img_shape = data.shape\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.fromarray(np.transpose(self.data[index]))\n",
    "        label = self.label[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img_to_tensor = transforms.ToTensor()\n",
    "            img = img_to_tensor(img)\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def plot_image(self, number):\n",
    "        file = self.data\n",
    "        label = self.label\n",
    "        fig = plt.figure(figsize = (3,2))\n",
    "        #img = return_photo(batch_file)\n",
    "        plt.imshow(file[number])\n",
    "        plt.title(classes[label[number]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "#features_train = torch.Tensor(features_train)\n",
    "#labels_train = torch.Tensor(labels_train)\n",
    "trainload = CIFARarray(features_train,labels_train,transform_train)\n",
    "trainloade = torch.utils.data.DataLoader(trainload, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "features_train_ = torch.Tensor(features_train)\n",
    "labels_train_ = torch.Tensor(labels_train)\n",
    "#features_train = features_train.type(torch.LongTensor)\n",
    "#labels_train = labels_train.type(torch.LongTensor)\n",
    "\n",
    "tmp = TensorDataset(features_train_,labels_train_)\n",
    "tmp = torch.utils.data.DataLoader(tmp, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader = CIFARarray(features_train,labels_train,transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader = torch.utils.data.DataLoader(trainloader, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainloader[0][1] == trainset[0][1]\n",
    "#print(label)\n",
    "#print(img.shape)\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "a = Image.fromarray(np.transpose(features_train[12],(1,2,0)))\n",
    "#plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = iter(tmp).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-575-e09fb7fa70e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!!!!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py382/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloade, 0):\n",
    "        print('!!!!!!!')\n",
    "        img, label = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        print(img.type())\n",
    "        print(label.type())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(img)\n",
    "        print(outputs.type())\n",
    "        #print(outputs.type())\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py382] *",
   "language": "python",
   "name": "conda-env-py382-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
